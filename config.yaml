parameters:
  input_size: 3
  action_size: 1
  k_step: 1
  hidden_size: 16
  num_layers: 1
  bias: True
  num_epochs: 1000
  lr: 0.0001
  save: True
  prefix: ''
  curr_learning: False
  pre_trained_path: './checkpoints/lstm_auto_encoder/checkpoint_16h_1step.pth'
