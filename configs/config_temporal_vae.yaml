input_size: 2
action_size: 1
k_step: 1
hidden_size: 16
latent_size: 4
num_layers: 1
batch_size: 32
bias: True
beta: 0.0001
num_epochs: 20
lr: 0.0001
save: True
encoding: 'nonlinear'
model_type: ''
prefix: '_decoder'
curr_learning: False
pre_trained_path: ''
